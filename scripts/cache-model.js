/**
 * ê°œë°œìš© ëª¨ë¸ ë¯¸ë¦¬ ìºì‹± ìŠ¤í¬ë¦½íŠ¸
 * node scripts/cache-model.js ì‹¤í–‰
 */

import { pipeline, env } from '@xenova/transformers';

// ê°œë°œìš©: ë¡œì»¬ ìºì‹œ ê²½ë¡œ ì„¤ì •
env.allowLocalModels = true;
env.allowRemoteModels = true;

async function cacheModel() {
  console.log('ğŸ”„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...');

  const models = [
    {
      name: 'Xenova/flan-t5-small',  // ê°€ë²¼ìš´ ëª¨ë¸ (ì•½ 200MB)
      task: 'text2text-generation'
    },
    // í•„ìš”ì‹œ ì¶”ê°€ ëª¨ë¸
  ];

  for (const model of models) {
    try {
      console.log(`\nğŸ“¦ ${model.name} ë‹¤ìš´ë¡œë“œ ì¤‘...`);

      const progress = {};
      const generator = await pipeline(model.task, model.name, {
        quantized: true,
        progress_callback: (data) => {
          if (data.status === 'downloading') {
            const pct = data.progress || 0;
            if (!progress[data.file]) {
              progress[data.file] = 0;
            }
            if (pct - progress[data.file] > 0.1) {
              progress[data.file] = pct;
              console.log(`  ${data.file}: ${(pct * 100).toFixed(0)}%`);
            }
          } else if (data.status === 'done') {
            console.log(`  âœ… ${data.file}`);
          }
        }
      });

      // ê°„ë‹¨ í…ŒìŠ¤íŠ¸
      const output = await generator('Hello, world!', { max_length: 10 });
      console.log(`  âœ… í…ŒìŠ¤íŠ¸ í†µê³¼: ${output[0].generated_text}`);

    } catch (error) {
      console.error(`  âŒ ì—ëŸ¬: ${error.message}`);
    }
  }

  console.log('\nâœ¨ ìºì‹± ì™„ë£Œ!');
  console.log('ğŸ“‚ ìºì‹œ ìœ„ì¹˜:');

  // Windows
  if (process.platform === 'win32') {
    console.log(`  ${process.env.LOCALAPPDATA}\\@xenova\\transformers\\`);
  }
  // macOS/Linux
  else {
    console.log(`  ~/.cache/@xenova/transformers/`);
  }
}

cacheModel().catch(console.error);
